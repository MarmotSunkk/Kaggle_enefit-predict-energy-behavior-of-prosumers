{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-20T23:30:47.170678Z",
     "iopub.status.busy": "2024-01-20T23:30:47.170240Z",
     "iopub.status.idle": "2024-01-20T23:30:47.562734Z",
     "shell.execute_reply": "2024-01-20T23:30:47.561620Z",
     "shell.execute_reply.started": "2024-01-20T23:30:47.170638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/predict-energy-behavior-of-prosumers/client.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/gas_prices.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/electricity_prices.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/weather_station_to_county_mapping.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/public_timeseries_testing_util.py\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/historical_weather.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/county_id_to_name_map.json\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/train.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/forecast_weather.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/sample_submission.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/client.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/gas_prices.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/electricity_prices.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/historical_weather.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/revealed_targets.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/test.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/forecast_weather.csv\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/enefit/competition.cpython-310-x86_64-linux-gnu.so\n",
      "/kaggle/input/predict-energy-behavior-of-prosumers/enefit/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:30:47.565121Z",
     "iopub.status.busy": "2024-01-20T23:30:47.564687Z",
     "iopub.status.idle": "2024-01-20T23:30:49.704134Z",
     "shell.execute_reply": "2024-01-20T23:30:49.702895Z",
     "shell.execute_reply.started": "2024-01-20T23:30:47.565090Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import holidays\n",
    "import os  # 操作系统相关功能\n",
    "import sys  # 提供对 Python 解释器的访问\n",
    "import gc  # 垃圾回收模块\n",
    "import time  # 时间模块\n",
    "import math  # 数学函数模块\n",
    "import collections  # 集合模块\n",
    "import psutil  # 进程和系统状态信息模块\n",
    "import pickle  # 对象序列化和反序列化模块\n",
    "from datetime import date, datetime, timedelta  # 日期和时间相关模块\n",
    "from copy import deepcopy  # 复制对象模块\n",
    "from tqdm import tqdm  # 进度条模块\n",
    "\n",
    "import numpy as np  # 数组和矩阵操作库\n",
    "import pandas as pd  # 数据分析库\n",
    "import polars as pl  # 快速数据操作库\n",
    "\n",
    "import matplotlib.pyplot as plt  # 绘图库\n",
    "import seaborn as sns  # 数据可视化库\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf  # 时间序列分析模块\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error  # 均方误差指标\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, KFold, TimeSeriesSplit  # 不同的交叉验证方法\n",
    "from sklearn.compose import TransformedTargetRegressor  # 目标变换模块\n",
    "from sklearn.ensemble import VotingRegressor  # 集成回归器\n",
    "from sklearn.model_selection import cross_validate # 本地交叉验证\n",
    "\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "\n",
    "import optuna  # 超参数优化框架'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:30:49.706061Z",
     "iopub.status.busy": "2024-01-20T23:30:49.705703Z",
     "iopub.status.idle": "2024-01-20T23:30:49.714329Z",
     "shell.execute_reply": "2024-01-20T23:30:49.713186Z",
     "shell.execute_reply.started": "2024-01-20T23:30:49.706026Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算某指标的前n个时间单元的平均值和方差\n",
    "def calculate_mean_var(df: pd.DataFrame, n, column_name):\n",
    "    mean = pd.Series()\n",
    "    var = pd.Series()\n",
    "    for i in range(len(df)):\n",
    "        if i < n-1:\n",
    "            mean[i] = np.mean(df[column_name].loc[0:i])\n",
    "            var[i] = np.var(df[column_name].loc[0:i])\n",
    "        else:\n",
    "            mean[i] = np.mean(df[column_name].loc[i-n+1:i])\n",
    "            var[i] = np.var(df[column_name].loc[i-n+1:i])\n",
    "    df[column_name +'_former_' + str(n) + '_mean'] = mean\n",
    "    df[column_name +'_former_' + str(n) + '_var'] = var\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:30:49.717530Z",
     "iopub.status.busy": "2024-01-20T23:30:49.717095Z",
     "iopub.status.idle": "2024-01-20T23:30:49.727192Z",
     "shell.execute_reply": "2024-01-20T23:30:49.725717Z",
     "shell.execute_reply.started": "2024-01-20T23:30:49.717468Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_holidays_as_binary_features(df: pd.DataFrame):\n",
    "    estonian_holidays = holidays.country_holidays('EE', years=range(2021, 2025))\n",
    "    estonian_holidays_set = {date.strftime('%Y-%m-%d') for date in estonian_holidays.keys()}\n",
    "    # 获取年月日信息\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    df['day'] = df['datetime'].dt.day\n",
    "\n",
    "    # 根据年月日确定是否是公共假期\n",
    "    days = df['year'].astype(str) + '-' + df['month'].astype(str).str.zfill(2) + '-' + df['day'].astype(str).str.zfill(2)\n",
    "    df['country_holiday'] = days.isin(estonian_holidays_set) \n",
    "\n",
    "    df = df.drop(columns = ['year', 'month', 'day'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:30:49.729005Z",
     "iopub.status.busy": "2024-01-20T23:30:49.728670Z",
     "iopub.status.idle": "2024-01-20T23:30:49.743594Z",
     "shell.execute_reply": "2024-01-20T23:30:49.742240Z",
     "shell.execute_reply.started": "2024-01-20T23:30:49.728976Z"
    }
   },
   "outputs": [],
   "source": [
    "def join_target_on_date(target ,target1 ,days, suffix):\n",
    "    target1 = target[['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime']].copy()\n",
    "    target1['datetime'] += pd.to_timedelta(days, unit='D')\n",
    "    new_target = target1.rename(columns={\"target\": f\"target_{suffix}\"})\n",
    "    target = target.merge(new_target, left_on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], right_on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"inner\")\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:30:49.746487Z",
     "iopub.status.busy": "2024-01-20T23:30:49.745361Z",
     "iopub.status.idle": "2024-01-20T23:30:49.781456Z",
     "shell.execute_reply": "2024-01-20T23:30:49.780212Z",
     "shell.execute_reply.started": "2024-01-20T23:30:49.746451Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_eng1(train, client, gas, electricity, fw, hw, locations, df_target):\n",
    "    # 处理locations表\n",
    "    locations = locations.dropna()\n",
    "    locations = locations.drop_duplicates()\n",
    "    locations = locations.reset_index(drop = True)\n",
    "    locations['latitude'] = round(locations['latitude'],1)\n",
    "    locations['longitude'] = round(locations['longitude'],1)\n",
    "\n",
    "    # 将fw中的列标记为预测天气(_fw)\n",
    "    fw['origin_datetime'] = pd.to_datetime(fw['origin_datetime'])\n",
    "    fw['forecast_datetime'] = pd.to_datetime(fw['forecast_datetime'])\n",
    "    fw = fw.rename(columns={'origin_datetime': 'origin_datetime_fw',\n",
    "                                           'hours_ahead':'hours_ahead_fw',\n",
    "                                           'temperature':'temperature_fw',\n",
    "                                           'dewpoint':'dewpoint_fw',\n",
    "                                           'cloudcover_high':'cloudcover_high_fw',\n",
    "                                           'cloudcover_low':'cloudcover_low_fw',\n",
    "                                           'cloudcover_mid':'cloudcover_mid_fw',\n",
    "                                           'cloudcover_total':'cloudcover_total_fw',\n",
    "                                            '10_metre_u_wind_component':'10_metre_u_wind_component_fw',\n",
    "                                           '10_metre_v_wind_component':'10_metre_v_wind_component_fw',\n",
    "                                           'direct_solar_radiation':'direct_solar_radiation_fw',\n",
    "                                           'surface_solar_radiation_downwards':'surface_solar_radiation_downwards_fw',\n",
    "                                           'snowfall':'snowfall_fw',\n",
    "                                           'total_precipitation':'total_precipitation_fw'})\n",
    "    # 将经纬度小数点位数统一\n",
    "    fw['latitude'] = round(fw['latitude'],1)\n",
    "    fw['longitude'] = round(fw['longitude'],1)\n",
    "    \n",
    "    # 合并预测天气和经纬度信息\n",
    "    fw_loc = pd.merge(fw,locations,how=\"inner\",left_on=['longitude','latitude'],right_on=['longitude','latitude'])\n",
    "    \n",
    "    # 删掉['latitude', 'longitude', 'origin_datetime_fw', 'county_name', 'hours_ahead_fw']这些与预测无关的列。\n",
    "    # 若hours_ahead_fw删掉，原因是：在所有时间点，可用的天气预报数据只有一行（需要再次确定）。\n",
    "        # 若hours_ahead_fw不删，原因是：做预测的时间与预测时间的时间差会影响预测准确性，进而影响用户行为。\n",
    "    fw_loc = fw_loc.drop(columns = ['latitude', 'longitude', 'origin_datetime_fw', 'county_name']) \n",
    "    # 因为同一个城市占据多个经纬度点，多个经纬度点的数据求平均\n",
    "    fw_loc_groupby = fw_loc.groupby(['county', 'forecast_datetime']).mean()\n",
    "    fw_loc_groupby = fw_loc_groupby.reset_index()\n",
    "    fw_loc_groupby['forecast_datetime'] = pd.to_datetime(fw_loc_groupby['forecast_datetime'])\n",
    "\n",
    "    # 合并历史数据和位置信息\n",
    "    hw_loc = pd.merge(hw, locations, how = 'inner', left_on=['longitude','latitude'],right_on=['longitude','latitude'])\n",
    "    \n",
    "    # 丢弃与预测无关的['datetime', 'longitude', 'latitude']\n",
    "    hw_loc = hw_loc.drop(columns = [ 'longitude', 'latitude', 'county_name'])\n",
    "    \n",
    "    # 计算所有历史天气数据关于同一data_block_id和county的均值\n",
    "    hw_loc_groupby_mean = hw_loc.groupby(['datetime', 'county']).mean()\n",
    "    hw_loc_groupby_mean = hw_loc_groupby_mean.reset_index()\n",
    "    hw_loc_groupby_mean = hw_loc_groupby_mean.rename(columns={\n",
    "                                       'temperature':'temperature_hw_mean',\n",
    "                                       'dewpoint':'dewpoint_hw_mean',\n",
    "                                       'rain':'rain_hw_mean',\n",
    "                                       'snowfall':'snowfall_hw_mean',\n",
    "                                       'surface_pressure':'surface_pressure_hw_mean',\n",
    "                                       'cloudcover_high':'cloudcover_high_hw_mean',\n",
    "                                       'cloudcover_low':'cloudcover_low_hw_mean',\n",
    "                                       'cloudcover_mid':'cloudcover_mid_hw_mean',\n",
    "                                       'cloudcover_total':'cloudcover_total_hw_mean',\n",
    "                                       'windspeed_10m':'windspeed_10m_hw_mean',\n",
    "                                       'winddirection_10m':'winddirection_10m_hw_mean',\n",
    "                                       'shortwave_radiation':'shortwave_radiation_hw_mean',\n",
    "                                       'diffuse_radiation':'diffuse_radiation_hw_mean',\n",
    "                                       'direct_solar_radiation':'direct_solar_radiation_hw_mean',\n",
    "                                       })\n",
    "    \n",
    "    # 计算所有历史天气数据关于同一data_block_id和county的方差\n",
    "    hw_loc_groupby_var = hw_loc.groupby(['datetime', 'county']).var()\n",
    "    hw_loc_groupby_var = hw_loc_groupby_var.reset_index()\n",
    "    hw_loc_groupby_var = hw_loc_groupby_var.rename(columns={\n",
    "                                       'temperature':'temperature_hw_var',\n",
    "                                       'dewpoint':'dewpoint_hw_var',\n",
    "                                       'rain':'rain_hw_var',\n",
    "                                       'snowfall':'snowfall_hw_var',\n",
    "                                       'surface_pressure':'surface_pressure_hw_var',\n",
    "                                       'cloudcover_high':'cloudcover_high_hw_var',\n",
    "                                       'cloudcover_low':'cloudcover_low_hw_var',\n",
    "                                       'cloudcover_mid':'cloudcover_mid_hw_var',\n",
    "                                       'cloudcover_total':'cloudcover_total_hw_var',\n",
    "                                       'windspeed_10m':'windspeed_10m_hw_var',\n",
    "                                       'winddirection_10m':'winddirection_10m_hw_var',\n",
    "                                       'shortwave_radiation':'shortwave_radiation_hw_var',\n",
    "                                       'diffuse_radiation':'diffuse_radiation_hw_var',\n",
    "                                       'direct_solar_radiation':'direct_solar_radiation_hw_var',\n",
    "                                       })\n",
    "\n",
    "\n",
    "    # 合并历史天气的均值和方差信息\n",
    "    hw_loc_groupby = pd.merge(hw_loc_groupby_mean, hw_loc_groupby_var, how = 'inner', \n",
    "                            left_on = ['datetime', 'county'], right_on = ['datetime', 'county'])\n",
    "    hw_loc_groupby['datetime'] = pd.to_datetime(hw_loc_groupby['datetime'])\n",
    "    \n",
    "    # 重命名 'forecast_date' 列为 'datetime'\n",
    "    electricity.rename(columns={\"forecast_date\": \"datetime\"}, inplace=True)\n",
    "    # 在 'datetime' 列上添加一天的时间间隔\n",
    "    electricity['datetime'] =  pd.to_datetime(pd.to_datetime(electricity['datetime']) + pd.DateOffset(days=1))\n",
    "    \n",
    "    # 对于每一小时，计算electricity的前24小时均值和方差(要不要再计算下前一个周的？)\n",
    "    electricity = calculate_mean_var(electricity, 24, 'euros_per_mwh')\n",
    "    electricity = electricity.drop(columns = [ 'origin_date'])\n",
    "    electricity = electricity.rename(columns={\"euros_per_mwh\": \"euros_per_mwh_electric\", \n",
    "                                        \"euros_per_mwh_former_24_mean\": \"euros_per_mwh_former_24_mean_electric\",\n",
    "                                        \"euros_per_mwh_former_24_var\":\"euros_per_mwh_former_24_var_electric\"})\n",
    "    \n",
    "    \n",
    "    \n",
    "    gas['date'] =  pd.to_datetime(pd.to_datetime(gas['forecast_date']) + pd.Timedelta(days=1))\n",
    "    # 对于每一天，计算gas价格的前7天均值和方差\n",
    "    gas = calculate_mean_var(gas, 7, 'lowest_price_per_mwh')\n",
    "    gas = calculate_mean_var(gas, 7, 'highest_price_per_mwh')\n",
    "    \n",
    "    # 将gas的时间列删除\n",
    "    gas = gas.drop(columns = [ 'forecast_date','origin_date'])\n",
    "    \n",
    "    # 给汽油价格列重命名防止与电价价混淆\n",
    "    gas = gas.rename(columns={\"lowest_price_per_mwh\": \"lowest_price_per_mwh_gas\", \n",
    "                          \"highest_price_per_mwh\": \"highest_price_per_mwh_gas\",\n",
    "                          \"lowest_price_per_mwh_former_7_mean_gas\":\"lowest_price_per_mwh_former_7_mean_gas\",\n",
    "                          \"lowest_price_per_mwh_former_7_var_gas\":\"lowest_price_per_mwh_former_7_var_gas\",\n",
    "                          \"highest_price_per_mwh_former_7_mean_gas\":\"highest_price_per_mwh_former_7_mean_gas\",\n",
    "                          \"highest_price_per_mwh_former_7_var_gas\":\"highest_price_per_mwh_former_7_var_gas\"})\n",
    "    \n",
    "    \n",
    "    train['date'] = pd.to_datetime(train['datetime']).dt.date\n",
    "    # train = train.drop(columns = ['data_block_id'])\n",
    "    client['date'] =  pd.to_datetime(pd.to_datetime(client['date']) + pd.Timedelta(days=2)).dt.date\n",
    "    # client = client.drop(columns = ['data_block_id'])\n",
    "    tmp1 = pd.merge(train, client, how = 'inner', left_on=['date','product_type','county','is_business'], right_on = ['date','product_type','county','is_business'])\n",
    "    tmp1['datetime'] = pd.to_datetime(tmp1['datetime'])\n",
    "    tmp1['date'] = pd.to_datetime(tmp1['datetime']).dt.date\n",
    "    tmp1['date']= pd.to_datetime(tmp1['date'])\n",
    "    tmp1['hour'] = tmp1['datetime'].dt.hour\n",
    "    \n",
    "    print('tmp1的长度')\n",
    "    print(len(tmp1))\n",
    "    \n",
    "    tmp2 = pd.merge(tmp1, fw_loc_groupby, how = 'left', left_on = ['county', 'datetime'], right_on = ['county','forecast_datetime'])\n",
    "    print('tmp2的长度')\n",
    "    print(len(tmp2))\n",
    "    hw_loc_groupby['datetime'] = pd.to_datetime(hw_loc_groupby['datetime'])\n",
    "    tmp3 = pd.merge(tmp2, hw_loc_groupby, how = 'left', left_on = ['datetime', 'county'], right_on = ['datetime', 'county'])\n",
    "    print('tmp3的长度')\n",
    "    print(len(tmp3))\n",
    "    tmp4 = pd.merge(tmp3, electricity, how = 'left', left_on = ['datetime'], right_on = ['datetime'])\n",
    "    tmp4['date']= pd.to_datetime(tmp4['date'])\n",
    "    print('tmp4的长度')\n",
    "    print(len(tmp4))\n",
    "    # 合并tmp4和gas表（此时已合并所有train, client, fw, hw, electricity, gas共6个表）\n",
    "    \n",
    "    train_all = pd.merge(tmp4, gas, how = 'inner', left_on=['date'],right_on=['date'])\n",
    "    print('train_all的长度')\n",
    "    print(len(train_all))\n",
    "    \n",
    "    # 新建'week_num'列储存星期信息\n",
    "    train_all['week_num'] = train_all['datetime'].dt.day_name()\n",
    "    # 初始化新列is_weekend存储是否为周末\n",
    "    train_all['is_weekend'] = 0\n",
    "    # 选择 'week_num' 列中值为 ‘Saturday’ 或 ‘Sunday’ 的行，并将这些行的 'is_weekend' 设置为 1\n",
    "    train_all.loc[train_all['week_num'].isin(['Saturday', 'Sunday']), 'is_weekend'] = 1\n",
    "\n",
    "    # 将星期信息进行one-hot编码\n",
    "    # 隐藏的测试集里面只有Sunday，会导致训练时模型与测试时模型的数据列数不同，产生报错\n",
    "    # train_all_week_num = pd.get_dummies(train_all['week_num'])\n",
    "    # train_all = pd.concat([train_all, train_all_week_num], axis = 1)\n",
    "    train_all = train_all.drop(columns = ['week_num'])\n",
    "    \n",
    "    print('添加星期信息后train_all的长度')\n",
    "    print(len(train_all))\n",
    "    \n",
    "    # 新建时间信息\n",
    "    train_all['dayofyear'] = train_all['datetime'].dt.dayofyear\n",
    "    train_all['sin(dayofyear)'] = np.sin(np.pi * train_all['dayofyear'] / 183)\n",
    "    train_all['cos(dayofyear)'] = np.cos(np.pi * train_all['dayofyear'] / 183)\n",
    "    train_all['sin(hour)'] = np.sin(np.pi * train_all['hour'] / 12)\n",
    "    train_all['cos(hour)'] = np.cos(np.pi * train_all['hour'] / 12)\n",
    "\n",
    "    print('添加时间信息后train_all的长度')\n",
    "    print(len(train_all))\n",
    "    \n",
    "    # 添加节日信息\n",
    "    train_all = add_holidays_as_binary_features(train_all)\n",
    "    \n",
    "    print('添加节日信息后train_all的长度')\n",
    "    print(len(train_all))\n",
    "    \n",
    "    #填加target\n",
    "    target = df_target[['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime']].copy()\n",
    "    target1 = df_target[['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime']].copy()\n",
    "    target['datetime'] = pd.to_datetime(target['datetime'])\n",
    "    target1['datetime'] = pd.to_datetime(target['datetime'])\n",
    "    \n",
    "    target =join_target_on_date(target,target1,1, 1)\n",
    "    target =join_target_on_date(target,target1,2, 2)\n",
    "    target =join_target_on_date(target,target1,3, 3)\n",
    "    target =join_target_on_date(target,target1,4, 4)\n",
    "    target =join_target_on_date(target,target1,5, 5)\n",
    "    target =join_target_on_date(target,target1,6, 6)\n",
    "    target = join_target_on_date(target,target1,7, 7)\n",
    "    target = target.drop(columns = ['target'])\n",
    "    \n",
    "    #合并train_all与target\n",
    "    train_all = train_all.merge(target, on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "    \n",
    "    print('添加target信息后train_all的长度')\n",
    "    print(len(train_all))\n",
    "    \n",
    "    # print(train_all[:10000]['datetime'].unique())\n",
    "    # 最后删除与预测无关的列\n",
    "    train_all = train_all.drop(columns = ['date', 'datetime', 'forecast_datetime', 'row_id','prediction_unit_id'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #修改数据类型\n",
    "    # train_all[['Friday','Monday','Saturday','Sunday','Thursday','Tuesday','Wednesday','country_holiday']] = train_all[['Friday','Monday','Saturday','Sunday','Thursday','Tuesday','Wednesday','country_holiday']].astype(bool)\n",
    "    \n",
    "    object_list = ['is_business', 'is_consumption', 'country_holiday']\n",
    "    for col in object_list:\n",
    "        if col in train_all.columns:\n",
    "            train_all[col] = train_all[col].astype(bool)\n",
    "    \n",
    "    # train_all.info()\n",
    "    \n",
    "    # train_all = train_all.dropna()\n",
    "    #lightGBM是否可以包含空值\n",
    "    \n",
    "    return train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:30:49.783248Z",
     "iopub.status.busy": "2024-01-20T23:30:49.782814Z",
     "iopub.status.idle": "2024-01-20T23:31:05.685795Z",
     "shell.execute_reply": "2024-01-20T23:31:05.684738Z",
     "shell.execute_reply.started": "2024-01-20T23:30:49.783217Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_405/3694854227.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target['is_business'] = df_target['is_business'].astype(bool)\n",
      "/tmp/ipykernel_405/3694854227.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target['is_consumption'] = df_target['is_consumption'].astype(bool)\n",
      "/tmp/ipykernel_405/3694854227.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target['datetime'] = pd.to_datetime(df_target['datetime'])\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/kaggle/input/predict-energy-behavior-of-prosumers\"\n",
    "\n",
    "train = pd.read_csv(f'{DATA_PATH}/train.csv')\n",
    "gas = pd.read_csv(f'{DATA_PATH}/gas_prices.csv')\n",
    "client = pd.read_csv(f'{DATA_PATH}/client.csv')\n",
    "electricity = pd.read_csv(f'{DATA_PATH}/electricity_prices.csv')\n",
    "hw = pd.read_csv(f'{DATA_PATH}/historical_weather.csv')\n",
    "fw = pd.read_csv(f'{DATA_PATH}/forecast_weather.csv')\n",
    "locations =  pd.read_csv(f'{DATA_PATH}/weather_station_to_county_mapping.csv')\n",
    "\n",
    "# 测试时要求直接输入df_target\n",
    "df_target = train[['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime']]\n",
    "df_target['is_business'] = df_target['is_business'].astype(bool)\n",
    "df_target['is_consumption'] = df_target['is_consumption'].astype(bool)\n",
    "df_target['datetime'] = pd.to_datetime(df_target['datetime'])\n",
    "# 各个表中的data_block_id列去掉\n",
    "train = train.drop(columns = ['data_block_id'])\n",
    "gas = gas.drop(columns = ['data_block_id'])\n",
    "client = client.drop(columns = ['data_block_id'])\n",
    "electricity = electricity.drop(columns = ['data_block_id'])\n",
    "hw = hw.drop(columns = ['data_block_id'])\n",
    "fw = fw.drop(columns = ['data_block_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:31:05.687313Z",
     "iopub.status.busy": "2024-01-20T23:31:05.686975Z",
     "iopub.status.idle": "2024-01-20T23:32:02.203225Z",
     "shell.execute_reply": "2024-01-20T23:32:02.202082Z",
     "shell.execute_reply.started": "2024-01-20T23:31:05.687286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp1的长度\n",
      "2009712\n",
      "tmp2的长度\n",
      "2009712\n",
      "tmp3的长度\n",
      "2009712\n",
      "tmp4的长度\n",
      "2009712\n",
      "train_all的长度\n",
      "2009712\n",
      "添加星期信息后train_all的长度\n",
      "2009712\n",
      "添加时间信息后train_all的长度\n",
      "2009712\n",
      "添加节日信息后train_all的长度\n",
      "2009712\n",
      "添加target信息后train_all的长度\n",
      "2009712\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>eic_count</th>\n",
       "      <th>installed_capacity</th>\n",
       "      <th>hour</th>\n",
       "      <th>hours_ahead_fw</th>\n",
       "      <th>temperature_fw</th>\n",
       "      <th>...</th>\n",
       "      <th>sin(hour)</th>\n",
       "      <th>cos(hour)</th>\n",
       "      <th>country_holiday</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "      <th>target_6</th>\n",
       "      <th>target_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.793</td>\n",
       "      <td>False</td>\n",
       "      <td>108</td>\n",
       "      <td>952.89</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.774683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>107.129</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "      <td>952.89</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.774683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.106</td>\n",
       "      <td>False</td>\n",
       "      <td>108</td>\n",
       "      <td>952.89</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.831120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>81.920</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "      <td>952.89</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.831120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955</td>\n",
       "      <td>False</td>\n",
       "      <td>108</td>\n",
       "      <td>952.89</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.782994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009707</th>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>265.328</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>2188.20</td>\n",
       "      <td>21</td>\n",
       "      <td>43.0</td>\n",
       "      <td>13.916846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>False</td>\n",
       "      <td>245.319</td>\n",
       "      <td>296.073</td>\n",
       "      <td>146.381</td>\n",
       "      <td>172.973</td>\n",
       "      <td>260.560</td>\n",
       "      <td>266.683</td>\n",
       "      <td>271.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009708</th>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>2188.20</td>\n",
       "      <td>22</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.470825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009709</th>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>274.569</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>2188.20</td>\n",
       "      <td>22</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.470825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>290.231</td>\n",
       "      <td>299.806</td>\n",
       "      <td>159.128</td>\n",
       "      <td>190.316</td>\n",
       "      <td>238.254</td>\n",
       "      <td>302.144</td>\n",
       "      <td>254.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009710</th>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>2188.20</td>\n",
       "      <td>23</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.484033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009711</th>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>196.240</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>2188.20</td>\n",
       "      <td>23</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.484033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>False</td>\n",
       "      <td>200.718</td>\n",
       "      <td>177.056</td>\n",
       "      <td>161.650</td>\n",
       "      <td>183.756</td>\n",
       "      <td>189.933</td>\n",
       "      <td>188.689</td>\n",
       "      <td>195.707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2009184 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         county  is_business  product_type   target  is_consumption  \\\n",
       "0             0        False             1    0.793           False   \n",
       "1             0        False             1  107.129            True   \n",
       "2             0        False             1    2.106           False   \n",
       "3             0        False             1   81.920            True   \n",
       "4             0        False             1    0.955           False   \n",
       "...         ...          ...           ...      ...             ...   \n",
       "2009707      15         True             3  265.328            True   \n",
       "2009708      15         True             3    0.001           False   \n",
       "2009709      15         True             3  274.569            True   \n",
       "2009710      15         True             3    0.000           False   \n",
       "2009711      15         True             3  196.240            True   \n",
       "\n",
       "         eic_count  installed_capacity  hour  hours_ahead_fw  temperature_fw  \\\n",
       "0              108              952.89     0            34.0       12.774683   \n",
       "1              108              952.89     0            34.0       12.774683   \n",
       "2              108              952.89     1            35.0       12.831120   \n",
       "3              108              952.89     1            35.0       12.831120   \n",
       "4              108              952.89     2            36.0       12.782994   \n",
       "...            ...                 ...   ...             ...             ...   \n",
       "2009707         55             2188.20    21            43.0       13.916846   \n",
       "2009708         55             2188.20    22            44.0       12.470825   \n",
       "2009709         55             2188.20    22            44.0       12.470825   \n",
       "2009710         55             2188.20    23            45.0       11.484033   \n",
       "2009711         55             2188.20    23            45.0       11.484033   \n",
       "\n",
       "         ...  sin(hour)  cos(hour)  country_holiday  target_1  target_2  \\\n",
       "0        ...   0.000000   1.000000            False       NaN       NaN   \n",
       "1        ...   0.000000   1.000000            False       NaN       NaN   \n",
       "2        ...   0.258819   0.965926            False       NaN       NaN   \n",
       "3        ...   0.258819   0.965926            False       NaN       NaN   \n",
       "4        ...   0.500000   0.866025            False       NaN       NaN   \n",
       "...      ...        ...        ...              ...       ...       ...   \n",
       "2009707  ...  -0.707107   0.707107            False   245.319   296.073   \n",
       "2009708  ...  -0.500000   0.866025            False     0.000     0.000   \n",
       "2009709  ...  -0.500000   0.866025            False   290.231   299.806   \n",
       "2009710  ...  -0.258819   0.965926            False     0.000     0.000   \n",
       "2009711  ...  -0.258819   0.965926            False   200.718   177.056   \n",
       "\n",
       "         target_3  target_4  target_5  target_6  target_7  \n",
       "0             NaN       NaN       NaN       NaN       NaN  \n",
       "1             NaN       NaN       NaN       NaN       NaN  \n",
       "2             NaN       NaN       NaN       NaN       NaN  \n",
       "3             NaN       NaN       NaN       NaN       NaN  \n",
       "4             NaN       NaN       NaN       NaN       NaN  \n",
       "...           ...       ...       ...       ...       ...  \n",
       "2009707   146.381   172.973   260.560   266.683   271.112  \n",
       "2009708     0.000     0.000     0.101     0.000     0.000  \n",
       "2009709   159.128   190.316   238.254   302.144   254.907  \n",
       "2009710     0.000     0.000     0.000     0.000     0.000  \n",
       "2009711   161.650   183.756   189.933   188.689   195.707  \n",
       "\n",
       "[2009184 rows x 72 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all = feature_eng1(train, client, gas, electricity, fw, hw, locations, df_target)\n",
    "train_all = train_all[train_all[\"target\"].notnull()]\n",
    "train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:32:02.205397Z",
     "iopub.status.busy": "2024-01-20T23:32:02.204601Z",
     "iopub.status.idle": "2024-01-20T23:32:02.222790Z",
     "shell.execute_reply": "2024-01-20T23:32:02.221552Z",
     "shell.execute_reply.started": "2024-01-20T23:32:02.205362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2009184 entries, 0 to 2009711\n",
      "Data columns (total 72 columns):\n",
      " #   Column                                 Dtype  \n",
      "---  ------                                 -----  \n",
      " 0   county                                 int64  \n",
      " 1   is_business                            bool   \n",
      " 2   product_type                           int64  \n",
      " 3   target                                 float64\n",
      " 4   is_consumption                         bool   \n",
      " 5   eic_count                              int64  \n",
      " 6   installed_capacity                     float64\n",
      " 7   hour                                   int32  \n",
      " 8   hours_ahead_fw                         float64\n",
      " 9   temperature_fw                         float64\n",
      " 10  dewpoint_fw                            float64\n",
      " 11  cloudcover_high_fw                     float64\n",
      " 12  cloudcover_low_fw                      float64\n",
      " 13  cloudcover_mid_fw                      float64\n",
      " 14  cloudcover_total_fw                    float64\n",
      " 15  10_metre_u_wind_component_fw           float64\n",
      " 16  10_metre_v_wind_component_fw           float64\n",
      " 17  direct_solar_radiation_fw              float64\n",
      " 18  surface_solar_radiation_downwards_fw   float64\n",
      " 19  snowfall_fw                            float64\n",
      " 20  total_precipitation_fw                 float64\n",
      " 21  temperature_hw_mean                    float64\n",
      " 22  dewpoint_hw_mean                       float64\n",
      " 23  rain_hw_mean                           float64\n",
      " 24  snowfall_hw_mean                       float64\n",
      " 25  surface_pressure_hw_mean               float64\n",
      " 26  cloudcover_total_hw_mean               float64\n",
      " 27  cloudcover_low_hw_mean                 float64\n",
      " 28  cloudcover_mid_hw_mean                 float64\n",
      " 29  cloudcover_high_hw_mean                float64\n",
      " 30  windspeed_10m_hw_mean                  float64\n",
      " 31  winddirection_10m_hw_mean              float64\n",
      " 32  shortwave_radiation_hw_mean            float64\n",
      " 33  direct_solar_radiation_hw_mean         float64\n",
      " 34  diffuse_radiation_hw_mean              float64\n",
      " 35  temperature_hw_var                     float64\n",
      " 36  dewpoint_hw_var                        float64\n",
      " 37  rain_hw_var                            float64\n",
      " 38  snowfall_hw_var                        float64\n",
      " 39  surface_pressure_hw_var                float64\n",
      " 40  cloudcover_total_hw_var                float64\n",
      " 41  cloudcover_low_hw_var                  float64\n",
      " 42  cloudcover_mid_hw_var                  float64\n",
      " 43  cloudcover_high_hw_var                 float64\n",
      " 44  windspeed_10m_hw_var                   float64\n",
      " 45  winddirection_10m_hw_var               float64\n",
      " 46  shortwave_radiation_hw_var             float64\n",
      " 47  direct_solar_radiation_hw_var          float64\n",
      " 48  diffuse_radiation_hw_var               float64\n",
      " 49  euros_per_mwh_electric                 float64\n",
      " 50  euros_per_mwh_former_24_mean_electric  float64\n",
      " 51  euros_per_mwh_former_24_var_electric   float64\n",
      " 52  lowest_price_per_mwh_gas               float64\n",
      " 53  highest_price_per_mwh_gas              float64\n",
      " 54  lowest_price_per_mwh_former_7_mean     float64\n",
      " 55  lowest_price_per_mwh_former_7_var      float64\n",
      " 56  highest_price_per_mwh_former_7_mean    float64\n",
      " 57  highest_price_per_mwh_former_7_var     float64\n",
      " 58  is_weekend                             int64  \n",
      " 59  dayofyear                              int32  \n",
      " 60  sin(dayofyear)                         float64\n",
      " 61  cos(dayofyear)                         float64\n",
      " 62  sin(hour)                              float64\n",
      " 63  cos(hour)                              float64\n",
      " 64  country_holiday                        bool   \n",
      " 65  target_1                               float64\n",
      " 66  target_2                               float64\n",
      " 67  target_3                               float64\n",
      " 68  target_4                               float64\n",
      " 69  target_5                               float64\n",
      " 70  target_6                               float64\n",
      " 71  target_7                               float64\n",
      "dtypes: bool(3), float64(63), int32(2), int64(4)\n",
      "memory usage: 1.0 GB\n"
     ]
    }
   ],
   "source": [
    "train_all.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:32:02.227267Z",
     "iopub.status.busy": "2024-01-20T23:32:02.226263Z",
     "iopub.status.idle": "2024-01-20T23:32:05.131647Z",
     "shell.execute_reply": "2024-01-20T23:32:05.130009Z",
     "shell.execute_reply.started": "2024-01-20T23:32:02.227229Z"
    }
   },
   "outputs": [],
   "source": [
    "X_consume = train_all.drop(columns = ['target'])[train_all['is_consumption'] == 1].reset_index(drop = True)\n",
    "y_consume = train_all[train_all['is_consumption'] == 1]['target'].reset_index(drop = True)\n",
    "X_produce = train_all.drop(columns = ['target'])[train_all['is_consumption'] == 0].reset_index(drop = True)\n",
    "y_produce = train_all[train_all['is_consumption'] == 0]['target'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:32:05.133564Z",
     "iopub.status.busy": "2024-01-20T23:32:05.133220Z",
     "iopub.status.idle": "2024-01-20T23:32:06.762001Z",
     "shell.execute_reply": "2024-01-20T23:32:06.760843Z",
     "shell.execute_reply.started": "2024-01-20T23:32:05.133535Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_consume, X_test_consume, y_train_consume, y_test_consume = train_test_split(X_consume, y_consume,  test_size = 0.2, random_state = 1)\n",
    "X_train_produce, X_test_produce, y_train_produce, y_test_produce = train_test_split(X_produce, y_produce,  test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:32:06.763748Z",
     "iopub.status.busy": "2024-01-20T23:32:06.763429Z",
     "iopub.status.idle": "2024-01-20T23:32:06.770002Z",
     "shell.execute_reply": "2024-01-20T23:32:06.768910Z",
     "shell.execute_reply.started": "2024-01-20T23:32:06.763722Z"
    }
   },
   "outputs": [],
   "source": [
    "#def lgb_objective(trial):\n",
    "#     params = {\n",
    "#        \n",
    "#         'random_state'     : 42,\n",
    "#         'objective'        : 'l2',\n",
    "#         \"n_estimators\"     : trial.suggest_int(\"n_estimators\", 500, 1500),\n",
    "#         'learning_rate'    : trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "#         'num_leaves'       : trial.suggest_int('num_leaves', 20, 1000),\n",
    "#         'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#         'colsample_bynode' : trial.suggest_float('colsample_bynode', 0.5, 1.0),\n",
    "#         'lambda_l1'        : trial.suggest_float('lambda_l1', 1e-2, 10.0),\n",
    "#         'lambda_l2'        : trial.suggest_float('lambda_l2', 1e-2, 10.0),\n",
    "#         'min_data_in_leaf' : trial.suggest_int('min_data_in_leaf', 4, 256),\n",
    "#         'max_depth'        : trial.suggest_int('max_depth', 5, 10),\n",
    "#         'max_bin'          : trial.suggest_int('max_bin', 32, 1024),\n",
    "#     }\n",
    "\n",
    "     # Fit the model\n",
    "#     model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "#     model.fit(X_train_consume, y_train_consume)\n",
    "    \n",
    "#     y_pred_consume = model.predict(X_test_consume)\n",
    "\n",
    "#     return mean_absolute_error(y_test_consume, y_pred_consume)\n",
    "\n",
    "#study_lgb_consume = optuna.create_study(direction='minimize') \n",
    "#study_lgb_consume.optimize(lgb_objective, n_trials=10, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:32:06.771703Z",
     "iopub.status.busy": "2024-01-20T23:32:06.771397Z",
     "iopub.status.idle": "2024-01-20T23:32:06.778614Z",
     "shell.execute_reply": "2024-01-20T23:32:06.777640Z",
     "shell.execute_reply.started": "2024-01-20T23:32:06.771676Z"
    }
   },
   "outputs": [],
   "source": [
    "#def lgb_objective_1(trial):\n",
    "#     params = {\n",
    "#        \n",
    "#         'random_state'     : 42,\n",
    "#         'objective'        : 'l2',\n",
    "#         \"n_estimators\"     : trial.suggest_int(\"n_estimators\", 500, 1500),\n",
    "#         'learning_rate'    : trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "#         'num_leaves'       : trial.suggest_int('num_leaves', 20, 1000),\n",
    "#         'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#         'colsample_bynode' : trial.suggest_float('colsample_bynode', 0.5, 1.0),\n",
    "#         'lambda_l1'        : trial.suggest_float('lambda_l1', 1e-2, 10.0),\n",
    "#         'lambda_l2'        : trial.suggest_float('lambda_l2', 1e-2, 10.0),\n",
    "#         'min_data_in_leaf' : trial.suggest_int('min_data_in_leaf', 4, 256),\n",
    "#         'max_depth'        : trial.suggest_int('max_depth', 5, 10),\n",
    "#         'max_bin'          : trial.suggest_int('max_bin', 32, 1024),\n",
    "#     }\n",
    "#\n",
    "     # Fit the model\n",
    "#     model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "#     model.fit(X_train_produce, y_train_produce)\n",
    "    \n",
    "#     y_pred_produce = model.predict(X_test_produce)\n",
    "\n",
    "#     return mean_absolute_error(y_test_produce, y_pred_produce)\n",
    "\n",
    "#study_lgb_produce = optuna.create_study(direction='minimize') \n",
    "#study_lgb_produce.optimize(lgb_objective_1, n_trials=10, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:32:06.780394Z",
     "iopub.status.busy": "2024-01-20T23:32:06.780073Z",
     "iopub.status.idle": "2024-01-20T23:32:06.792766Z",
     "shell.execute_reply": "2024-01-20T23:32:06.791624Z",
     "shell.execute_reply.started": "2024-01-20T23:32:06.780367Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params_consume = {'n_estimators': 1431, 'learning_rate': 0.0551787862618339, 'num_leaves': 842, 'colsample_bytree': 0.7041692691308047, 'colsample_bynode': 0.9464257615398879, 'lambda_l1': 3.5553059277534813, 'lambda_l2': 9.699940077832881, 'min_data_in_leaf': 140, 'max_depth': 10, 'max_bin': 942}\n",
    "best_params_produce = {'n_estimators': 1456, 'learning_rate': 0.04792210443806526, 'num_leaves': 643, 'colsample_bytree': 0.7415703894708183, 'colsample_bynode': 0.6608787398677248, 'lambda_l1': 7.971511344337281, 'lambda_l2': 0.06719129003550212, 'min_data_in_leaf': 44, 'max_depth': 10, 'max_bin': 464}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:32:06.795561Z",
     "iopub.status.busy": "2024-01-20T23:32:06.794748Z",
     "iopub.status.idle": "2024-01-20T23:32:06.803411Z",
     "shell.execute_reply": "2024-01-20T23:32:06.802106Z",
     "shell.execute_reply.started": "2024-01-20T23:32:06.795503Z"
    }
   },
   "outputs": [],
   "source": [
    "model_consume = lgb.LGBMRegressor(**best_params_consume)\n",
    "model_produce = lgb.LGBMRegressor(**best_params_produce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:32:06.805722Z",
     "iopub.status.busy": "2024-01-20T23:32:06.804966Z",
     "iopub.status.idle": "2024-01-20T23:41:30.943206Z",
     "shell.execute_reply": "2024-01-20T23:41:30.941837Z",
     "shell.execute_reply.started": "2024-01-20T23:32:06.805685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3.5553059277534813, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5553059277534813\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.699940077832881, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.699940077832881\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bynode=0.6608787398677248,\n",
       "              colsample_bytree=0.7415703894708183, lambda_l1=7.971511344337281,\n",
       "              lambda_l2=0.06719129003550212, learning_rate=0.04792210443806526,\n",
       "              max_bin=464, max_depth=10, min_data_in_leaf=44, n_estimators=1456,\n",
       "              num_leaves=643)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bynode=0.6608787398677248,\n",
       "              colsample_bytree=0.7415703894708183, lambda_l1=7.971511344337281,\n",
       "              lambda_l2=0.06719129003550212, learning_rate=0.04792210443806526,\n",
       "              max_bin=464, max_depth=10, min_data_in_leaf=44, n_estimators=1456,\n",
       "              num_leaves=643)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(colsample_bynode=0.6608787398677248,\n",
       "              colsample_bytree=0.7415703894708183, lambda_l1=7.971511344337281,\n",
       "              lambda_l2=0.06719129003550212, learning_rate=0.04792210443806526,\n",
       "              max_bin=464, max_depth=10, min_data_in_leaf=44, n_estimators=1456,\n",
       "              num_leaves=643)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_consume.fit(\n",
    "    X=X_consume,\n",
    "    y=y_consume\n",
    ")\n",
    "\n",
    "model_produce.fit(\n",
    "    X=X_produce,\n",
    "    y=y_produce\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:41:30.944923Z",
     "iopub.status.busy": "2024-01-20T23:41:30.944579Z",
     "iopub.status.idle": "2024-01-20T23:41:30.962759Z",
     "shell.execute_reply": "2024-01-20T23:41:30.961937Z",
     "shell.execute_reply.started": "2024-01-20T23:41:30.944892Z"
    }
   },
   "outputs": [],
   "source": [
    "import enefit\n",
    "\n",
    "env = enefit.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:41:30.964768Z",
     "iopub.status.busy": "2024-01-20T23:41:30.964257Z",
     "iopub.status.idle": "2024-01-20T23:41:30.969120Z",
     "shell.execute_reply": "2024-01-20T23:41:30.967824Z",
     "shell.execute_reply.started": "2024-01-20T23:41:30.964736Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample_prediction[\"target\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:44:17.722772Z",
     "iopub.status.busy": "2024-01-20T23:44:17.722346Z",
     "iopub.status.idle": "2024-01-20T23:45:49.668160Z",
     "shell.execute_reply": "2024-01-20T23:45:49.667230Z",
     "shell.execute_reply.started": "2024-01-20T23:44:17.722740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "          target  county  is_business  product_type  is_consumption  \\\n",
      "0          0.713       0        False             1           False   \n",
      "1         96.590       0        False             1            True   \n",
      "2          0.000       0        False             2           False   \n",
      "3         17.314       0        False             2            True   \n",
      "4          2.904       0        False             3           False   \n",
      "...          ...     ...          ...           ...             ...   \n",
      "2018347  197.233      15         True             0            True   \n",
      "2018348    0.000      15         True             1           False   \n",
      "2018349   28.404      15         True             1            True   \n",
      "2018350    0.000      15         True             3           False   \n",
      "2018351  196.240      15         True             3            True   \n",
      "\n",
      "                   datetime  \n",
      "0       2021-09-01 00:00:00  \n",
      "1       2021-09-01 00:00:00  \n",
      "2       2021-09-01 00:00:00  \n",
      "3       2021-09-01 00:00:00  \n",
      "4       2021-09-01 00:00:00  \n",
      "...                     ...  \n",
      "2018347 2023-05-31 23:00:00  \n",
      "2018348 2023-05-31 23:00:00  \n",
      "2018349 2023-05-31 23:00:00  \n",
      "2018350 2023-05-31 23:00:00  \n",
      "2018351 2023-05-31 23:00:00  \n",
      "\n",
      "[2018352 rows x 6 columns]\n",
      "tmp1的长度\n",
      "3120\n",
      "tmp2的长度\n",
      "3120\n",
      "tmp3的长度\n",
      "3120\n",
      "tmp4的长度\n",
      "3120\n",
      "train_all的长度\n",
      "3120\n",
      "添加星期信息后train_all的长度\n",
      "3120\n",
      "添加时间信息后train_all的长度\n",
      "3120\n",
      "添加节日信息后train_all的长度\n",
      "3120\n",
      "添加target信息后train_all的长度\n",
      "3120\n",
      "          target  county  is_business  product_type  is_consumption  \\\n",
      "0          0.713       0        False             1           False   \n",
      "1         96.590       0        False             1            True   \n",
      "2          0.000       0        False             2           False   \n",
      "3         17.314       0        False             2            True   \n",
      "4          2.904       0        False             3           False   \n",
      "...          ...     ...          ...           ...             ...   \n",
      "2018347  197.233      15         True             0            True   \n",
      "2018348    0.000      15         True             1           False   \n",
      "2018349   28.404      15         True             1            True   \n",
      "2018350    0.000      15         True             3           False   \n",
      "2018351  196.240      15         True             3            True   \n",
      "\n",
      "                   datetime  \n",
      "0       2021-09-01 00:00:00  \n",
      "1       2021-09-01 00:00:00  \n",
      "2       2021-09-01 00:00:00  \n",
      "3       2021-09-01 00:00:00  \n",
      "4       2021-09-01 00:00:00  \n",
      "...                     ...  \n",
      "2018347 2023-05-31 23:00:00  \n",
      "2018348 2023-05-31 23:00:00  \n",
      "2018349 2023-05-31 23:00:00  \n",
      "2018350 2023-05-31 23:00:00  \n",
      "2018351 2023-05-31 23:00:00  \n",
      "\n",
      "[2018352 rows x 6 columns]\n",
      "tmp1的长度\n",
      "3120\n",
      "tmp2的长度\n",
      "3120\n",
      "tmp3的长度\n",
      "3120\n",
      "tmp4的长度\n",
      "3120\n",
      "train_all的长度\n",
      "3120\n",
      "添加星期信息后train_all的长度\n",
      "3120\n",
      "添加时间信息后train_all的长度\n",
      "3120\n",
      "添加节日信息后train_all的长度\n",
      "3120\n",
      "添加target信息后train_all的长度\n",
      "3120\n",
      "          target  county  is_business  product_type  is_consumption  \\\n",
      "0          0.713       0        False             1           False   \n",
      "1         96.590       0        False             1            True   \n",
      "2          0.000       0        False             2           False   \n",
      "3         17.314       0        False             2            True   \n",
      "4          2.904       0        False             3           False   \n",
      "...          ...     ...          ...           ...             ...   \n",
      "2018347  197.233      15         True             0            True   \n",
      "2018348    0.000      15         True             1           False   \n",
      "2018349   28.404      15         True             1            True   \n",
      "2018350    0.000      15         True             3           False   \n",
      "2018351  196.240      15         True             3            True   \n",
      "\n",
      "                   datetime  \n",
      "0       2021-09-01 00:00:00  \n",
      "1       2021-09-01 00:00:00  \n",
      "2       2021-09-01 00:00:00  \n",
      "3       2021-09-01 00:00:00  \n",
      "4       2021-09-01 00:00:00  \n",
      "...                     ...  \n",
      "2018347 2023-05-31 23:00:00  \n",
      "2018348 2023-05-31 23:00:00  \n",
      "2018349 2023-05-31 23:00:00  \n",
      "2018350 2023-05-31 23:00:00  \n",
      "2018351 2023-05-31 23:00:00  \n",
      "\n",
      "[2018352 rows x 6 columns]\n",
      "tmp1的长度\n",
      "3120\n",
      "tmp2的长度\n",
      "3120\n",
      "tmp3的长度\n",
      "3120\n",
      "tmp4的长度\n",
      "3120\n",
      "train_all的长度\n",
      "3120\n",
      "添加星期信息后train_all的长度\n",
      "3120\n",
      "添加时间信息后train_all的长度\n",
      "3120\n",
      "添加节日信息后train_all的长度\n",
      "3120\n",
      "添加target信息后train_all的长度\n",
      "3120\n",
      "          target  county  is_business  product_type  is_consumption  \\\n",
      "0          0.713       0        False             1           False   \n",
      "1         96.590       0        False             1            True   \n",
      "2          0.000       0        False             2           False   \n",
      "3         17.314       0        False             2            True   \n",
      "4          2.904       0        False             3           False   \n",
      "...          ...     ...          ...           ...             ...   \n",
      "2018347  197.233      15         True             0            True   \n",
      "2018348    0.000      15         True             1           False   \n",
      "2018349   28.404      15         True             1            True   \n",
      "2018350    0.000      15         True             3           False   \n",
      "2018351  196.240      15         True             3            True   \n",
      "\n",
      "                   datetime  \n",
      "0       2021-09-01 00:00:00  \n",
      "1       2021-09-01 00:00:00  \n",
      "2       2021-09-01 00:00:00  \n",
      "3       2021-09-01 00:00:00  \n",
      "4       2021-09-01 00:00:00  \n",
      "...                     ...  \n",
      "2018347 2023-05-31 23:00:00  \n",
      "2018348 2023-05-31 23:00:00  \n",
      "2018349 2023-05-31 23:00:00  \n",
      "2018350 2023-05-31 23:00:00  \n",
      "2018351 2023-05-31 23:00:00  \n",
      "\n",
      "[2018352 rows x 6 columns]\n",
      "tmp1的长度\n",
      "3120\n",
      "tmp2的长度\n",
      "3120\n",
      "tmp3的长度\n",
      "3120\n",
      "tmp4的长度\n",
      "3120\n",
      "train_all的长度\n",
      "3120\n",
      "添加星期信息后train_all的长度\n",
      "3120\n",
      "添加时间信息后train_all的长度\n",
      "3120\n",
      "添加节日信息后train_all的长度\n",
      "3120\n",
      "添加target信息后train_all的长度\n",
      "3120\n"
     ]
    }
   ],
   "source": [
    "for (test, revealed_targets, client, historical_weather,\n",
    "        forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n",
    "    \n",
    "    test = test.rename(columns={'prediction_datetime': 'datetime'})\n",
    "    test = test.drop(columns = ['currently_scored'])\n",
    "    \n",
    "    df_forecast       = pd.concat([fw, forecast_weather]).reset_index(drop = True).drop_duplicates()\n",
    "    df_historical     = pd.concat([hw, historical_weather]).reset_index(drop = True).drop_duplicates()\n",
    "    revealed_targets = revealed_targets.drop(columns = ['row_id', 'prediction_unit_id'])\n",
    "    df_target         = pd.concat([df_target, revealed_targets]).reset_index(drop = True).drop_duplicates()\n",
    "    print(df_target)\n",
    "    \n",
    "    X_test = feature_eng1(test, client, gas_prices, electricity_prices, df_forecast, df_historical, locations, df_target)\n",
    "    \n",
    "    test['target'] = model_consume.predict(X_test).clip(0)\n",
    "    test['target_solar'] = model_produce.predict(X_test).clip(0)\n",
    "    test.loc[test['is_consumption']==0, 'target'] = test.loc[test['is_consumption']==0, 'target_solar']  \n",
    "    \n",
    "    sample_prediction['target'] = test['target']\n",
    "    \n",
    "    \n",
    "    # sample_prediction[\"target\"] = model.predict(X_test).clip(0)\n",
    "    env.predict(sample_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7292407,
     "sourceId": 57236,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
